{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b11a06-7976-4b4b-b4e2-a69e84dd4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.covariance import LedoitWolf, MinCovDet\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(252525)\n",
    "torch.manual_seed(252525)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from meanshift import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8023d4ce-57bd-4f77-864e-039ea95b4217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = models.efficientnet_b4(pretrained=True).features\n",
    "net = net.to(device)\n",
    "net = net.eval()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb1a3da9-8d42-46e4-8dd5-e9798adea778",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle 0.9976190476190476\n",
      "carpet 0.9333868378812198\n",
      "leather 1.0\n",
      "pill 0.9015275504637207\n",
      "tile 0.9873737373737375\n",
      "wood 0.9956140350877192\n",
      "cable 0.9439655172413794\n",
      "grid 0.9039264828738512\n",
      "toothbrush 0.9805555555555556\n",
      "zipper 0.983718487394958\n",
      "capsule 0.9234144395692063\n",
      "hazelnut 0.9917857142857143\n",
      "metal_nut 0.9281524926686217\n",
      "screw 0.7200245952039355\n",
      "transistor 0.9616666666666667\n",
      "bottle 0.9976190476190476\n",
      "carpet 0.9333868378812198\n",
      "leather 1.0\n",
      "pill 0.9015275504637207\n",
      "tile 0.9873737373737375\n",
      "wood 0.9956140350877192\n",
      "cable 0.9439655172413794\n",
      "grid 0.9039264828738512\n",
      "toothbrush 0.9805555555555556\n",
      "zipper 0.983718487394958\n",
      "capsule 0.9234144395692063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137129/3827355051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/mean-shift/meanshift/helpers/patch_utils.py\u001b[0m in \u001b[0;36mconcat_features\u001b[0;34m(X, eff, layers, bs, fmap_pool, debug)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/mean-shift/meanshift/helpers/patch_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "clazz = 3\n",
    "epochs = 1\n",
    "augment = False\n",
    "\n",
    "log = []\n",
    "\n",
    "for run in range(2):\n",
    "\n",
    "    for clazz in range(15):\n",
    "\n",
    "        X_, X_valid_, X_test_, X_labels_, T = zip(*[dataloader(clazz, P=224, s=224, label_per_patch=False, augment=augment) for i in range(epochs)])\n",
    "        X_, X_valid_, X_test_ = np.concatenate(X_), np.concatenate(X_valid_), np.concatenate(X_test_)\n",
    "\n",
    "        scores_inliers = []\n",
    "        scores_outliers = []\n",
    "\n",
    "        for l in range(9):\n",
    "\n",
    "            X = concat_features(X_, net, layers=[l], fmap_pool=False)\n",
    "            X_valid = concat_features(X_valid_, net, layers=[l], fmap_pool=False)\n",
    "            X_test = concat_features(X_test_, net, layers=[l], fmap_pool=False)\n",
    "\n",
    "            # Pooling training\n",
    "            n = X.shape[0]\n",
    "            X__ = X.mean((2,3))\n",
    "            #X__ = X__.reshape(n, -1)\n",
    "\n",
    "            C_inv = LedoitWolf().fit(X__).precision_\n",
    "            mu = X__.mean(0)\n",
    "\n",
    "            # Pooling inliers\n",
    "            n_valid = len(X_valid)\n",
    "            X_valid__ = X_valid.mean((2,3)) - mu\n",
    "            #X_valid_ = X_valid_.reshape(n_valid, -1)\n",
    "\n",
    "            # Pooling outliers\n",
    "            n_test = len(X_test)\n",
    "            X_test__ = X_test.mean((2,3)) - mu\n",
    "            #X_test_ = X_test_.reshape(n_test, -1)\n",
    "\n",
    "            # Mahalanobis\n",
    "            M_valid_ = np.sqrt( ( X_valid__ * ( C_inv @ X_valid__.T ).T ).sum(1) )    \n",
    "            M_test_  = np.sqrt( ( X_test__ * ( C_inv @ X_test__.T ).T ).sum(1) )    \n",
    "\n",
    "            scores_inliers.append(M_valid_)\n",
    "            scores_outliers.append(M_test_)\n",
    "\n",
    "        auc = roc_auc_score([0] * n_valid + [1] * n_test, np.concatenate([np.asarray(scores_inliers).sum(0), np.asarray(scores_outliers).sum(0)]))\n",
    "\n",
    "        log.append(pd.DataFrame(np.asarray([run, clazz, l, n, auc])[:, None].T, columns=[\"run\", \"class\", \"layers\", \"n_samples\", \"auc\"])) \n",
    "\n",
    "        print(MVTEC.CLASSES[clazz], auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2771e777-9911-413d-9d7e-40df4f459af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class=bottle    , n_samples=209 \tauc: 0.998 ± 0.000\n",
      "class=carpet    , n_samples=280 \tauc: 0.933 ± 0.000\n",
      "class=leather   , n_samples=245 \tauc: 1.000 ± 0.000\n",
      "class=pill      , n_samples=267 \tauc: 0.902 ± 0.000\n",
      "class=tile      , n_samples=230 \tauc: 0.987 ± 0.000\n",
      "class=wood      , n_samples=247 \tauc: 0.996 ± 0.000\n",
      "class=cable     , n_samples=224 \tauc: 0.944 ± 0.000\n",
      "class=grid      , n_samples=264 \tauc: 0.904 ± 0.000\n",
      "class=toothbrush, n_samples= 60 \tauc: 0.981 ± 0.000\n",
      "class=zipper    , n_samples=240 \tauc: 0.984 ± 0.000\n",
      "class=capsule   , n_samples=219 \tauc: 0.923 ± 0.000\n",
      "class=hazelnut  , n_samples=391 \tauc: 0.992 ± nan\n",
      "class=metal_nut , n_samples=220 \tauc: 0.928 ± nan\n",
      "class=screw     , n_samples=320 \tauc: 0.720 ± nan\n",
      "class=transistor, n_samples=213 \tauc: 0.962 ± nan\n",
      "0.9616666666666667\n"
     ]
    }
   ],
   "source": [
    "log_ = pd.concat(log)\n",
    "\n",
    "for clazz in range(15):\n",
    "    auc = log_[ (log_[\"class\"] == clazz) ].groupby(\"run\").mean()[\"auc\"]\n",
    "    n = int(log_[ (log_[\"class\"] == clazz) ].groupby(\"run\").mean()[\"n_samples\"].mean())\n",
    "    print(f\"class={MVTEC.CLASSES[clazz]:10s}, n_samples={n:3d}\", f\"\\tauc: {auc.mean():.3f}\", \"\\u00B1\", f\"{auc.std():.3f}\" )\n",
    "\n",
    "avg = log_[ (log_[\"class\"] == clazz) ].groupby(\"run\").mean()[\"auc\"].mean()\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbff632-71a4-4cc9-a598-1f31852a651c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9815a57-9554-42df-aed2-2d17e0f1b98c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure in class:0, n:10, l:0\n",
      "bottle 0.984920634920635\n",
      "Failure in class:1, n:10, l:0\n",
      "carpet 0.812199036918138\n",
      "leather 0.9972826086956521\n",
      "pill 0.73240589198036\n",
      "tile 0.9794372294372294\n",
      "wood 0.9868421052631579\n",
      "cable 0.8290854572713644\n",
      "grid 0.6482873851294904\n",
      "toothbrush 0.8944444444444445\n",
      "zipper 0.9642857142857142\n",
      "Failure in class:10, n:10, l:0\n",
      "capsule 0.7483047467092142\n",
      "hazelnut 0.8385714285714285\n",
      "metal_nut 0.8470185728250244\n",
      "screw 0.5763476122156179\n",
      "Failure in class:14, n:10, l:0\n",
      "transistor 0.8529166666666667\n",
      "bottle 0.9880952380952381\n",
      "carpet 0.9542536115569823\n",
      "leather 0.9952445652173914\n",
      "Failure in class:3, n:10, l:0\n",
      "pill 0.7452264048008729\n",
      "tile 0.9823232323232324\n",
      "wood 0.9850877192982456\n",
      "cable 0.8615067466266866\n",
      "grid 0.6942355889724311\n",
      "toothbrush 0.95\n",
      "zipper 0.9569327731092436\n",
      "capsule 0.8607897885919427\n",
      "hazelnut 0.9010714285714286\n",
      "metal_nut 0.8543499511241447\n",
      "screw 0.46320967411354785\n",
      "transistor 0.8687499999999999\n",
      "bottle 0.9952380952380953\n",
      "carpet 0.9482343499197431\n",
      "leather 0.998641304347826\n",
      "pill 0.7626841243862521\n",
      "tile 0.9844877344877346\n",
      "wood 0.9964912280701754\n",
      "cable 0.8774362818590705\n",
      "grid 0.6532999164578113\n",
      "toothbrush 0.9388888888888889\n",
      "zipper 0.9740021008403361\n",
      "capsule 0.9042680494615077\n",
      "hazelnut 0.9082142857142858\n",
      "metal_nut 0.8875855327468231\n",
      "screw 0.5447837671654028\n",
      "transistor 0.9170833333333333\n",
      "bottle 0.9968253968253968\n",
      "carpet 0.9626805778491172\n",
      "leather 0.998641304347826\n",
      "pill 0.7967812329514459\n",
      "tile 0.9852092352092353\n",
      "wood 0.9921052631578947\n",
      "cable 0.860944527736132\n",
      "grid 0.7351712614870509\n",
      "toothbrush 0.9583333333333334\n",
      "zipper 0.9703256302521008\n",
      "capsule 0.8747506980454727\n",
      "hazelnut 0.9164285714285715\n",
      "metal_nut 0.8802541544477028\n",
      "screw 0.6384505021520803\n",
      "transistor 0.9529166666666666\n",
      "bottle 0.9992063492063492\n",
      "carpet 0.9578651685393258\n",
      "leather 1.0\n",
      "pill 0.8046917621385706\n",
      "tile 0.9855699855699855\n",
      "wood 0.9964912280701754\n",
      "cable 0.9002998500749626\n",
      "grid 0.8596491228070174\n",
      "toothbrush 0.9694444444444444\n",
      "zipper 0.9834558823529411\n",
      "capsule 0.9361786996410053\n",
      "hazelnut 0.9342857142857143\n",
      "metal_nut 0.8748778103616813\n",
      "screw 0.7142857142857144\n",
      "transistor 0.9345833333333334\n",
      "bottle 0.9992063492063492\n",
      "carpet 0.9606741573033708\n",
      "leather 1.0\n",
      "pill 0.8139661756683032\n",
      "tile 0.9812409812409812\n",
      "wood 0.9973684210526315\n",
      "cable 0.8607571214392804\n",
      "grid 0.8262322472848788\n",
      "toothbrush 0.9805555555555556\n",
      "zipper 0.9855567226890756\n",
      "capsule 0.9258077383326686\n",
      "hazelnut 0.9360714285714286\n",
      "metal_nut 0.8934506353861191\n",
      "screw 0.5958188153310104\n",
      "transistor 0.9362499999999999\n",
      "bottle 0.9992063492063492\n",
      "carpet 0.9674959871589085\n",
      "leather 1.0\n",
      "pill 0.8199672667757774\n",
      "tile 0.9870129870129871\n",
      "wood 0.9938596491228071\n",
      "cable 0.889055472263868\n",
      "grid 0.8721804511278196\n",
      "toothbrush 0.9805555555555555\n",
      "zipper 0.9831932773109244\n",
      "capsule 0.9313921021140805\n",
      "hazelnut 0.9671428571428572\n",
      "metal_nut 0.9340175953079178\n",
      "screw 0.7788481246156999\n",
      "transistor 0.9516666666666667\n",
      "bottle 1.0\n",
      "carpet 0.9674959871589084\n",
      "leather 0.9976222826086957\n",
      "pill 0.8251500272776867\n",
      "tile 0.9877344877344877\n",
      "wood 0.9982456140350878\n",
      "cable 0.9196026986506746\n",
      "grid 0.8738512949039264\n",
      "toothbrush 0.9805555555555555\n",
      "zipper 0.9826680672268908\n",
      "capsule 0.9282010370961309\n",
      "hazelnut 0.9532142857142857\n",
      "metal_nut 0.9325513196480938\n",
      "screw 0.7556876409100226\n",
      "transistor 0.9479166666666666\n",
      "bottle 0.9976190476190476\n",
      "carpet 0.9630818619582664\n",
      "leather 0.998641304347826\n",
      "pill 0.8715220949263501\n",
      "tile 0.9855699855699857\n",
      "wood 0.9982456140350878\n",
      "cable 0.9152923538230885\n",
      "grid 0.8822055137844611\n",
      "toothbrush 0.9805555555555555\n",
      "zipper 0.9829306722689075\n",
      "capsule 0.92381332269645\n",
      "hazelnut 0.9835714285714285\n",
      "metal_nut 0.9110459433040078\n",
      "screw 0.7023980323836851\n",
      "transistor 0.9566666666666666\n",
      "bottle 1.0\n",
      "carpet 0.9670947030497592\n",
      "leather 0.998641304347826\n",
      "pill 0.8319694489907257\n",
      "tile 0.9877344877344877\n",
      "wood 0.9956140350877194\n",
      "cable 0.9119190404797601\n",
      "grid 0.8688387635756056\n",
      "toothbrush 0.9805555555555555\n",
      "zipper 0.9852941176470589\n",
      "capsule 0.9369764658954927\n",
      "hazelnut 0.972857142857143\n",
      "metal_nut 0.9198435972629521\n",
      "screw 0.7415453986472638\n",
      "transistor 0.95\n"
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "epochs = 1\n",
    "\n",
    "log = []\n",
    "\n",
    "for n in [10, 25, 50, 80, 100]: #1, 5, \n",
    "    for run in range(2):\n",
    "\n",
    "        for clazz in range(15):\n",
    "\n",
    "            X_, X_valid_, X_test_, X_labels_, T = zip(*[dataloader(clazz, P=224, s=224, label_per_patch=False, augment=augment) for i in range(epochs)])\n",
    "            X_, X_valid_, X_test_ = np.concatenate(X_), np.concatenate(X_valid_), np.concatenate(X_test_)\n",
    "            X_ = X_[np.random.permutation(len(X_))[:n]]\n",
    "\n",
    "            scores_inliers = []\n",
    "            scores_outliers = []\n",
    "\n",
    "            for l in range(9):\n",
    "\n",
    "                X = concat_features(X_, net, blocks=[l], fmap_pool=False)\n",
    "                X_valid = concat_features(X_valid_, net, blocks=[l], fmap_pool=False)\n",
    "                X_test = concat_features(X_test_, net, blocks=[l], fmap_pool=False)\n",
    "\n",
    "                # Pooling training\n",
    "                m = X.shape[0]\n",
    "                X__ = X.mean((2,3))\n",
    "                #X__ = X__.reshape(n, -1)\n",
    "                \n",
    "                try:\n",
    "                    C_inv = LedoitWolf().fit(X__).precision_\n",
    "                    mu = X__.mean(0)\n",
    "\n",
    "                    # Pooling inliers\n",
    "                    n_valid = len(X_valid)\n",
    "                    X_valid__ = X_valid.mean((2,3)) - mu\n",
    "                    #X_valid_ = X_valid_.reshape(n_valid, -1)\n",
    "\n",
    "                    # Pooling outliers\n",
    "                    n_test = len(X_test)\n",
    "                    X_test__ = X_test.mean((2,3)) - mu\n",
    "                    #X_test_ = X_test_.reshape(n_test, -1)\n",
    "\n",
    "                    # Mahalanobis\n",
    "                    M_valid_ = np.sqrt( ( X_valid__ * ( C_inv @ X_valid__.T ).T ).sum(1) )    \n",
    "                    M_test_  = np.sqrt( ( X_test__ * ( C_inv @ X_test__.T ).T ).sum(1) )    \n",
    "\n",
    "                    scores_inliers.append(M_valid_)\n",
    "                    scores_outliers.append(M_test_)\n",
    "                except:\n",
    "                    print(f\"Failure in class:{clazz}, n:{n}, l:{l}\")\n",
    "\n",
    "            auc = roc_auc_score([0] * n_valid + [1] * n_test, np.concatenate([np.asarray(scores_inliers).sum(0), np.asarray(scores_outliers).sum(0)]))\n",
    "\n",
    "            log.append(pd.DataFrame(np.asarray([run, clazz, l, n, auc])[:, None].T, columns=[\"run\", \"class\", \"layers\", \"n_samples\", \"auc\"])) \n",
    "\n",
    "            print(MVTEC.CLASSES[clazz], auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "611675d2-8c7c-47ec-921c-783e773fc47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   5.,  10.,  25.,  50.,  80., 100.]),\n",
       " array([0.5       , 0.831542  , 0.87037206, 0.89370525, 0.9181281 ,\n",
       "        0.9368697 , 0.9367348 ], dtype=float32),\n",
       " array([0.        , 0.00013533, 0.02060096, 0.01077063, 0.00744486,\n",
       "        0.00024028, 0.00020155]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.concat(log)\n",
    "\n",
    "x = dat[[\"run\", \"class\", \"auc\", \"n_samples\"]].astype(np.float32).groupby(\"n_samples\").mean().index\n",
    "y = dat[[\"run\", \"class\", \"auc\", \"n_samples\"]].astype(np.float32).groupby(\"n_samples\").mean()[\"auc\"]\n",
    "s = dat[[\"run\", \"class\", \"auc\", \"n_samples\"]].astype(np.float32).groupby([\"run\", \"n_samples\"]).mean().groupby([ \"n_samples\"]).std()[\"auc\"]\n",
    "\n",
    "np.asarray(x), np.asarray(y), np.asarray(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88dfb50-d219-45cc-8173-fceaeb413c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
